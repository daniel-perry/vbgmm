<html>
<head>
<title>Gaussian Mixture Models using Variational Bayes</title>
<!--
////////////////////////////////////
// The MIT License
//
// Copyright (c) 2012 Daniel Perry.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the "Software"),
// to deal in the Software without restriction, including without limitation
// the rights to use, copy, modify, merge, publish, distribute, sublicense,
// and/or sell copies of the Software, and to permit persons to whom the
// Software is furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
// THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
// FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
// DEALINGS IN THE SOFTWARE.
////////////////////////////////////////
-->
</head>
<script type="text/javascript" src="LaTeXMathML.js"></script>
<script type="text/javascript" src="underscore.js"></script>
<!--
<script type="text/javascript" src="jquery-1.8.1.min.js"></script>
-->
<script type="text/javascript" src="script.js"></script>
<link rel="stylesheet" type="text/css" href="style.css"></link>

<body>

<div align="center" id="title" name="title" class="section">
	<h1 style="padding-top: 100px;">Gaussian Mixture Models using Variational Bayes</h1>
	<h3>by Daniel Perry</h3>
	<h4 style="padding-top: 100px;">presentation url:</h4>
	  	<p>
		 		to follow along: <a href="http://www.cs.utah.edu/~dperry/class/seminar/vbgmm">www.cs.utah.edu/~dperry/class/seminar/vbgmm</a>
			</p>
	  	<p>
				to post comments/suggestions: <a href="http://images-and-data.blogspot.com">images-and-data.blogspot.com</a>
			</p>
</div>


<div id="kmeans" name="kmeans" class="section">
	<h2>K-means clustering</h2>

	<div id="kmeans_def" class="subsection">
	Goal: cluster similar data together
	<ul>
  <li> data: N points of a D-dimensional data set, $\{x_1,...,x_N\}$, where $x_i$ refers to the i<sup>th</sup> point</li>
	<li> similarity: requires some measure of similarity, we'll use Euclidean distance.</li>
	<li> cluster membership: clusters will be described by center value, and each point will only belong to a single cluster. <br>
  	Notation:
		<ul>
		<li>$\mu_k$ describes the center of the k<sup>th</sup> cluster.</li>
		<li>membership will be denoted with a "1-of-K" vector, $r_{nk} \in \{0,1\}$ corresponding to each $x_i$.<br>$r_{ik} = 1$ and $r_{ij} = 0$ for $j\nek$ if $x_{i}$ belongs to cluster $k$.
    </li>
<!-- TODO: add visual of this? -->
	  </ul>
  </li>
	</ul>
  </div>

  <div id="kmeans_objective" class="subsection">

  <p>We can define an objective function:</p>
  <p>$J = \sum_n\sum_k r_{nk}||x_n-\mu_k||^2$ &nbsp;&nbsp;&nbsp;(1)</p>
  <p>Which corresponds to the "sum of squares" of each point to its assigned cluster center.</p>

	<p> The real goal is to minimize $J$, ie find the values of $\mu$ and $r$ that minimize $J$.</p>
	
	<p> The optimal $\mu$ and $r$ can be derived analytically from $J$, but we will only describe the derivation here.</p>

  <ul>
  <li><b>cluster center:</b><br>
  derivation: the cluster center that minimizes the sum of squares to every point in the cluster, is the mean:<br>
  $\vec{\mu_k} = (\sum_nr_{nk}\vec{x_n})/(\sum_nr_{ik})$ &nbsp;&nbsp;&nbsp;(2)
  </li>
  <li><b>cluster membership:</b><br>
  derivation: the cluster membership that minimizes sum of squares to the mean, is the cluster with the closest center: <br>
  $r_{nk} = 1 &nbsp;&nbsp;if $ $k=arg min_j ||\vec{x_n} - \vec{\mu_j}||^2$, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(3)<br>$r_{nk} = 0$ otherwise.
  </li>
  </ul>

	<p>Note the circular dependency above betwen $\mu_k$ and $r_{\cdot k}$ (cluster mean and cluster membership)</p>
  </div>

  <div id="kmeans_steps" class="subsection">
	<p>Because of this circular dependency, we find the optimum by iteratively switching between them, until there is no change.</p>
  <p>(note: this is guaranteed to find a local optimum, but not the global optimum)</p>
  Steps:
  <ol>
  <li> $\mu$ initialized randomly. </li>
	<li> Solve for $r$ using (3). </li>
  <li> Solve for $\mu$ using (2). </li>
  <li> Repeat steps 2 and 3, until $\mu$ and $r$ don't change. </li>
  </ol>
  </div>

	<canvas id="kmeans_example1" width="500" height="500">
	</canvas>

</div>

<div id="gmm" name="gmm" class="section">
<a name="gmm"></a>
	<h2>Gaussian Mixture Models (GMM)</h2>
	<div id="gmm_definition" class="subsection">
		<h3>Definition</h3>
	</div>
	<div id="gmm_kmeans" class="subsection">
		<h3>K-means as GMM</h3>
	</div>
	<div id="gmm_ml" class="subsection">
		<h3>GMM Maximum Likelihood</h3>
	</div>
</div>

<div id="em" name="em" class="section">
	<h2>Expectation-Maximization</h2>
	<div id="em_definition" class="subsection">
	</div>
	<div id="em_gmm" class="subsection">
	</div>
</div>

<div id="vb" name="vb" class="section">
	<h2>Variational Bayes</h2>
	<div id="vb_bayes" class="subsection">
		<h3>Bayes formulation</h3>
	</div>
	<div id="vb_estimation" class="subsection">
	  <h3>Variational Inference</h3>
	</div>
</div>

<div id="references" name="references" class="section">
	<h2>Presentation URL</h2>
		<ul>
	  	<li>
		 		to review: <a href="http://www.cs.utah.edu/~dperry/class/seminar/vbgmm">www.cs.utah.edu/~dperry/class/seminar/vbgmm</a>
			</li>
	  	<li>
				to post comments/suggestions: <a href="http://images-and-data.blogspot.com">images-and-data.blogspot.com</a>
			</li>
		</ul>
	<h2>References</h2>
	<ol>
		<li>
			Bishop, Christopher M. (2006). "Pattern Recognition and Machine Learning". Springer. ISBN 0-387-31073-8.
			(sections 10.2 and 9.4)
		</li>
		<li>
			<a href="http://research.microsoft.com/~cmbishop/downloads/Bishop-AIStats01.pdf" target="_blank">http://research.microsoft.com/~cmbishop/downloads/Bishop-AIStats01.pdf</a>
		</li>
		<li>
			<a href="http://www.goldenmetallic.com/research/uai99.pdf" target="_blank">http://www.goldenmetallic.com/research/uai99.pdf</a>
		</li>
		<li>
			<a href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods" target="_blank">https://en.wikipedia.org/wiki/Variational_Bayesian_methods</a>
		</li>
	</ol>
</div>


</body>
</html>

